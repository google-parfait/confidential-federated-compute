name: Reusable build and attest

on:
  workflow_call:
    inputs:
      name:
        required: true
        type: string
      module-root:
        required: true
        type: string
    secrets:
      gcp-credentials:
        required: true

jobs:

  # Run a bazel build and upload the resulting binaries.
  build:
    permissions:
      contents: read

    runs-on: large-4cpu-16gbRAM-150gbSSD-ubuntu24.04

    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Setup Bazel
        uses: bazel-contrib/setup-bazel@0.15.0
        with:
          module-root: ${{ inputs.module-root }}
          bazelisk-cache: true
          disk-cache: ${{ github.workflow }}-${{ inputs.name }}
      - name: Build
        run: |
          cd "${{ inputs.module-root }}" && bazelisk run -c opt --curses=no --noshow_progress //:install_release_binaries -- --destdir="${{ runner.temp }}/binaries"
      - name: Upload binaries
        uses: actions/upload-artifact@v4
        with:
          name: binaries-${{ inputs.name }}
          path: ${{ runner.temp }}/binaries/
          if-no-files-found: error
          retention-days: 5

  # Produce a JSON-encoded list of all binaries produced by the `build` step.
  list-binaries:
    needs: build

    outputs:
      binaries: ${{ steps.list.outputs.binaries }}

    permissions: {}

    runs-on: ubuntu-latest

    steps:
      - name: Download binaries
        uses: actions/download-artifact@v4
        with:
          pattern: binaries-${{ inputs.name }}
          path: ${{ runner.temp }}/binaries
          merge-multiple: true

      - name: List binaries
        id: list
        # Set the "binaries" output to a json-encoded list of the bazel build
        # artifacts. (e.g. ["agg_core/container.tar","ledger/binary"])
        run: |
          set -euxo pipefail
          binaries="$(find "${{ runner.temp }}/binaries" -type f -printf '%P\n' | jq -Rsc 'split("\n")[:-1]')"
          echo "binaries=${binaries}" >> "$GITHUB_OUTPUT"

  # For each binary listed by the `list-binaries` step, generate signed build
  # provenance. Provenance needs to be generated for each binary independently
  # because Oak doesn't support reading multi-subject provenance. Provenance is
  # then uploaded to Rekor and GCS.
  attest:
    needs: list-binaries

    permissions:
      id-token: write
      attestations: write

    runs-on: ubuntu-latest

    strategy:
      # Continue attesting other artifacts even if one fails.
      fail-fast: false
      matrix:
        binary: ${{ fromJson(needs.list-binaries.outputs.binaries) }}

    steps:
      - name: Download binaries
        uses: actions/download-artifact@v4
        with:
          pattern: binaries-*
          merge-multiple: true
      - name: Attest
        id: attest
        uses: actions/attest-build-provenance@v1
        with:
          subject-path: ${{ matrix.binary }}
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.gcp-credentials }}
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          skip_install: true
      - name: Upload provenance
        run: |
          set -euxo pipefail

          binary_path="${{ matrix.binary }}"
          package_name="${binary_path%%/*}"
          provenance_path="${{ steps.attest.outputs.bundle-path }}"
          gcs_provenance_path="provenance/${GITHUB_SHA}/${package_name}/attestation.jsonl"

          gcloud storage cp --no-clobber "${provenance_path}" "gs://oak-bins/${gcs_provenance_path}"

          phash_path=$(mktemp)
          phash="sha2-256:$(sha256sum "${provenance_path}" | cut -d " " -f 1)"
          echo "${phash}" > "${phash_path}"
          gcloud storage cp --no-clobber "${provenance_path}" "gs://oak-files/${phash}"
          gcloud storage cp --no-clobber "${phash_path}" "gs://oak-index/7/sha1:${GITHUB_SHA}/${package_name}"
